{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.5. DL_Tensorflow_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junheeyoon/colab/blob/main/4_5_DL_Tensorflow_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl2BJ7FAZXaU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JNZV44O2NbP"
      },
      "source": [
        "# Tensorflow 과제\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQF2e_Np221F"
      },
      "source": [
        "## CNN기초\r\n",
        "원본 데이터를 2차원으로 놓고 필터(또는 feature detector)라는 사각형 윈도우를 씌운다음에 움직이면서 새로운 값을 만들어 낸다.\r\n",
        "이때 움직이는 과정을 convolution이라고 하고, 필터가 움직이는 방향이 한 방향이면 1D-CNN이고 두 방향이면 2D-CNN이다.\r\n",
        "\r\n",
        "1차원 CNN이라 하더라도 필터의 사각형이 반드시 1차원인건 아니다. 움직이는 콘볼루션 방향및 결과로 나오는 배열이 1차원인지 2차원인지 따지는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xpsJSF1lLPx"
      },
      "source": [
        "## 2D CNN으로 MNIST 데이터 분류 (워밍업)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7pxMEnP64uF"
      },
      "source": [
        "### 데이터 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2-nXBLr6QbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d653f8-6633-4e7d-a613-53a6e3c7fa3e"
      },
      "source": [
        "import keras\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, Conv1D, MaxPooling2D\r\n",
        "from keras import backend as k\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "#load mnist dataset\r\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() #everytime loading data won't be so easy :)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuXwLCgM9pbv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d304ec45-3ccf-420a-8c8e-2ddc9cd36063"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "fig = plt.figure()\r\n",
        "for i in range(9):\r\n",
        "  plt.subplot(3,3,i+1)\r\n",
        "  plt.tight_layout()\r\n",
        "  plt.imshow(X_train[i], cmap='gray', interpolation='none')\r\n",
        "  plt.title(\"Digit: {}\".format(y_train[i]))\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOecVWpL-vlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0883252a-8230-4cde-f61f-52160fd30c1e"
      },
      "source": [
        "# let's print the actual data shape before we reshape and normalize\r\n",
        "print(\"X_train shape\", X_train.shape)\r\n",
        "print(\"y_train shape\", y_train.shape)\r\n",
        "print(\"X_test shape\", X_test.shape)\r\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfb1pCGwAJCZ"
      },
      "source": [
        "#input image size 28*28\r\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shd_jU1rAKnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ca1495-4707-48d9-bae5-5100702aadfe"
      },
      "source": [
        "#reshaping\r\n",
        "#this assumes our data format\r\n",
        "#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \r\n",
        "#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\r\n",
        "if k.image_data_format() == 'channels_first':\r\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\r\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\r\n",
        "    input_shape = (1, img_rows, img_cols)\r\n",
        "else:\r\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\r\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\r\n",
        "    input_shape = (img_rows, img_cols, 1)\r\n",
        "#more reshaping\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "X_train /= 255\r\n",
        "X_test /= 255\r\n",
        "print('X_train shape:', X_train.shape)\r\n",
        "print(X_train.shape[0], 'train samples')\r\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug6Ifz6_CEEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb4b890-5a6e-42ed-c459-a020dd35a1ee"
      },
      "source": [
        "print(np.unique(y_train, return_counts=True))\r\n",
        "#set number of categories\r\n",
        "num_category = 10\r\n",
        "# convert class vectors to binary class matrices\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_category)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_category)\r\n",
        "y_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmhrRmnCmc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04fe351-4567-421b-8c27-d5d431b33caa"
      },
      "source": [
        "##model building\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\r\n",
        "model = Sequential()\r\n",
        "#convolutional layer with rectified linear unit activation\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\r\n",
        "                 activation='relu',\r\n",
        "                 input_shape=input_shape))\r\n",
        "#32 convolution filters used each of size 3x3\r\n",
        "#again\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "#64 convolution filters used each of size 3x3\r\n",
        "#choose the best features via pooling\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "#randomly turn neurons on and off to improve convergence\r\n",
        "model.add(Dropout(0.25))\r\n",
        "#flatten since too many dimensions, we only want a classification output\r\n",
        "model.add(Flatten())\r\n",
        "#fully connected to get all relevant data\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "#one more dropout for convergence' sake :) \r\n",
        "model.add(Dropout(0.5))\r\n",
        "#output a softmax to squash the matrix into output probabilities\r\n",
        "model.add(Dense(num_category, activation='softmax'))\r\n",
        "#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\r\n",
        "#categorical ce since we have multiple classes (10) \r\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\r\n",
        "              optimizer=keras.optimizers.Adadelta(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "num_epoch = 10\r\n",
        "\r\n",
        "#model training\r\n",
        "model_log = model.fit(\r\n",
        "    X_train, \r\n",
        "    y_train,\r\n",
        "    batch_size=batch_size,\r\n",
        "    epochs=num_epoch,\r\n",
        "    verbose=1,\r\n",
        "    validation_data=(X_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 11s 9ms/step - loss: 2.2952 - accuracy: 0.1398 - val_loss: 2.2393 - val_accuracy: 0.4227\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 2.2333 - accuracy: 0.2655 - val_loss: 2.1624 - val_accuracy: 0.5396\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 2.1584 - accuracy: 0.3693 - val_loss: 2.0601 - val_accuracy: 0.6133\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 2.0589 - accuracy: 0.4478 - val_loss: 1.9245 - val_accuracy: 0.6584\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.9289 - accuracy: 0.4966 - val_loss: 1.7551 - val_accuracy: 0.6956\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.7745 - accuracy: 0.5354 - val_loss: 1.5612 - val_accuracy: 0.7283\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.6108 - accuracy: 0.5694 - val_loss: 1.3657 - val_accuracy: 0.7560\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.4463 - accuracy: 0.6075 - val_loss: 1.1872 - val_accuracy: 0.7794\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.3047 - accuracy: 0.6357 - val_loss: 1.0389 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.1797 - accuracy: 0.6640 - val_loss: 0.9203 - val_accuracy: 0.8153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YP13-o6adMD"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1torQqUmDmK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7480f4-3d49-466c-a7de-274e2a7c490b"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.9203364253044128\n",
            "Test accuracy: 0.8152999877929688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5K6as2mk9PH"
      },
      "source": [
        "## 1D CNN으로 MNIST 데이터 분류 (메인, 인터넷에서 찾지 말고 가능한 자신이 구현해 볼 것)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj61AJDSZRX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9cb439-be67-48bd-8d1e-4b2fd2fbd31e"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "# 모양 (shape) 확인\r\n",
        "print('X_train shape', X_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHMExmAg74ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4783e6d1-422f-45ba-8042-25aa93d29eb3"
      },
      "source": [
        "from keras.layers import Embedding\r\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\r\n",
        "from keras.layers import Dense, Dropout, Activation\r\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "train_images = train_images.reshape((60000, 784, 1)) \r\n",
        "test_images = test_images.reshape((10000, 784, 1)) \r\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\r\n",
        "\r\n",
        "model = Sequential() #모델 생성.\r\n",
        "\r\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=(784, 1)))  #Conv1D 모델을 추가한다.\r\n",
        "\r\n",
        "model.add(MaxPooling1D(2)) #Maxpooling 추가를 한다.\r\n",
        "\r\n",
        "model.add(Conv1D(32, 3, activation='relu'))\r\n",
        "\r\n",
        "model.add(MaxPooling1D(2))\r\n",
        "\r\n",
        "model.add(Conv1D(32, 3, activation='relu'))\r\n",
        "\r\n",
        "model.add(Flatten()) \r\n",
        "\r\n",
        "model.add(Dense(32, activation='relu')) \r\n",
        "\r\n",
        "model.add(Dense(10, activation='softmax')) \r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(train_images, train_labels, epochs=1,verbose=1) \r\n",
        "\r\n",
        "_, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3911 - accuracy: 0.8778\n",
            "313/313 - 1s - loss: 0.1083 - accuracy: 0.9678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhb2MaBzez90"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "# one-hot encoding\r\n",
        "Y_train = to_categorical(y_train)\r\n",
        "Y_test = to_categorical(y_test)\r\n",
        "print('Y_train.shape', Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSJR7dc5fBzm"
      },
      "source": [
        "from keras.layers import Embedding\r\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\r\n",
        "from keras.layers import Dense, Dropout, Activation\r\n",
        "\r\n",
        "max_features = 5000\r\n",
        "maxlen = 784\r\n",
        "embedding_dims = 50\r\n",
        "filters = 250\r\n",
        "kernel_size = 3\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\r\n",
        "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1))\r\n",
        "model.add(GlobalMaxPooling1D())\r\n",
        "model.add(Dense(10))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "\r\n",
        "#model.add(Dense(128, input_shape=(784,), activation='relu'))\r\n",
        "#model.add(Dense(84, activation='relu'))\r\n",
        "#model.add(Dense(10, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "batch_size = 128\r\n",
        "num_epoch = 10\r\n",
        "hist = model.fit(X_train, Y_train,batch_size=batch_size,\r\n",
        "    epochs=num_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoj0rETmfjyE"
      },
      "source": [
        "train_acc = hist.history['accuracy'][-1]\r\n",
        "train_loss =  hist.history['loss'][-1]\r\n",
        "\r\n",
        "print('train accuracy: ', train_acc)\r\n",
        "print('train loss: ', train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMukjpgsov6F"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}