{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-5.DL - Tensorflow Assignment.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN2eC89OBhHnF7Ceyw9khLn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junheeyoon/colab/blob/main/4_5_DL_Tensorflow_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JNZV44O2NbP"
      },
      "source": [
        "# Tensorflow 과제\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQF2e_Np221F"
      },
      "source": [
        "## CNN기초\r\n",
        "원본 데이터를 2차원으로 놓고 필터(또는 feature detector)라는 사각형 윈도우를 씌운다음에 움직이면서 새로운 값을 만들어 낸다.\r\n",
        "이때 움직이는 과정을 convolution이라고 하고, 필터가 움직이는 방향이 한 방향이면 1D-CNN이고 두 방향이면 2D-CNN이다.\r\n",
        "\r\n",
        "1차원 CNN이라 하더라도 필터의 사각형이 반드시 1차원인건 아니다. 움직이는 콘볼루션 방향및 결과로 나오는 배열이 1차원인지 2차원인지 따지는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xpsJSF1lLPx"
      },
      "source": [
        "## 2D CNN으로 MNIST 데이터 분류 (워밍업)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7pxMEnP64uF"
      },
      "source": [
        "### 데이터 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2-nXBLr6QbC"
      },
      "source": [
        "import keras\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\r\n",
        "from keras import backend as k\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "#load mnist dataset\r\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() #everytime loading data won't be so easy :)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuXwLCgM9pbv"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "fig = plt.figure()\r\n",
        "for i in range(9):\r\n",
        "  plt.subplot(3,3,i+1)\r\n",
        "  plt.tight_layout()\r\n",
        "  plt.imshow(X_train[i], cmap='gray', interpolation='none')\r\n",
        "  plt.title(\"Digit: {}\".format(y_train[i]))\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOecVWpL-vlJ"
      },
      "source": [
        "# let's print the actual data shape before we reshape and normalize\r\n",
        "print(\"X_train shape\", X_train.shape)\r\n",
        "print(\"y_train shape\", y_train.shape)\r\n",
        "print(\"X_test shape\", X_test.shape)\r\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfb1pCGwAJCZ"
      },
      "source": [
        "#input image size 28*28\r\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shd_jU1rAKnG"
      },
      "source": [
        "#reshaping\r\n",
        "#this assumes our data format\r\n",
        "#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \r\n",
        "#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\r\n",
        "if k.image_data_format() == 'channels_first':\r\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\r\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\r\n",
        "    input_shape = (1, img_rows, img_cols)\r\n",
        "else:\r\n",
        "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\r\n",
        "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\r\n",
        "    input_shape = (img_rows, img_cols, 1)\r\n",
        "#more reshaping\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "X_train /= 255\r\n",
        "X_test /= 255\r\n",
        "print('X_train shape:', X_train.shape)\r\n",
        "print(X_train.shape[0], 'train samples')\r\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug6Ifz6_CEEC"
      },
      "source": [
        "print(np.unique(y_train, return_counts=True))\r\n",
        "#set number of categories\r\n",
        "num_category = 10\r\n",
        "# convert class vectors to binary class matrices\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_category)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_category)\r\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmhrRmnCmc4"
      },
      "source": [
        "##model building\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\r\n",
        "model = Sequential()\r\n",
        "#convolutional layer with rectified linear unit activation\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\r\n",
        "                 activation='relu',\r\n",
        "                 input_shape=input_shape))\r\n",
        "#32 convolution filters used each of size 3x3\r\n",
        "#again\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "#64 convolution filters used each of size 3x3\r\n",
        "#choose the best features via pooling\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "#randomly turn neurons on and off to improve convergence\r\n",
        "model.add(Dropout(0.25))\r\n",
        "#flatten since too many dimensions, we only want a classification output\r\n",
        "model.add(Flatten())\r\n",
        "#fully connected to get all relevant data\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "#one more dropout for convergence' sake :) \r\n",
        "model.add(Dropout(0.5))\r\n",
        "#output a softmax to squash the matrix into output probabilities\r\n",
        "model.add(Dense(num_category, activation='softmax'))\r\n",
        "#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\r\n",
        "#categorical ce since we have multiple classes (10) \r\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\r\n",
        "              optimizer=keras.optimizers.Adadelta(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "num_epoch = 10\r\n",
        "\r\n",
        "#model training\r\n",
        "model_log = model.fit(\r\n",
        "    X_train, \r\n",
        "    y_train,\r\n",
        "    batch_size=batch_size,\r\n",
        "    epochs=num_epoch,\r\n",
        "    verbose=1,\r\n",
        "    validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1torQqUmDmK8"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5K6as2mk9PH"
      },
      "source": [
        "## 1D CNN으로 MNIST 데이터 분류 (메인, 인터넷에서 찾지 말고 가능한 자신이 구현해 볼 것)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj61AJDSZRX-"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "# 모양 (shape) 확인\r\n",
        "print('X_train shape', X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In5HsNjBeQCx"
      },
      "source": [
        "# Train\r\n",
        "X_train_size = X_train.shape[0]\r\n",
        "input_dim = X_train.shape[1] *  X_train.shape[2]\r\n",
        "X_train = np.reshape(X_train, (X_train_size, input_dim))\r\n",
        "print(X_train.shape)\r\n",
        "# Test\r\n",
        "X_test_size = X_test.shape[0]\r\n",
        "input_dim = X_test.shape[1] *  X_test.shape[2]\r\n",
        "X_test = np.reshape(X_test, (X_test_size, input_dim))\r\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhb2MaBzez90"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "# one-hot encoding\r\n",
        "Y_train = to_categorical(y_train)\r\n",
        "Y_test = to_categorical(y_test)\r\n",
        "print('Y_train.shape', Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSJR7dc5fBzm"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(128, input_shape=(784,), activation='relu'))\r\n",
        "model.add(Dense(84, activation='relu'))\r\n",
        "model.add(Dense(10, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "batch_size = 128\r\n",
        "num_epoch = 10\r\n",
        "hist = model.fit(X_train, Y_train,batch_size=batch_size,\r\n",
        "    epochs=num_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoj0rETmfjyE"
      },
      "source": [
        "train_acc = hist.history['accuracy'][-1]\r\n",
        "train_loss =  hist.history['loss'][-1]\r\n",
        "\r\n",
        "print('train accuracy: ', train_acc)\r\n",
        "print('train loss: ', train_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMukjpgsov6F"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}